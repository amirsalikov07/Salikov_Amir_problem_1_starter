# Salikov_Amir_problem_1_starter
Здесь находится код задания 1 по курсу "Нейронные сети в обработке изображений"
LBL1 - выбираем устройство вычислений \\
LBL2 - фиксируем число классов для нашей задачи и статистики нормализации как в ImageNet \\
LBL3  - загрузка предобученной модели EfficientNet-B0
LBL4  - замена «головы» под число классов
LBL5  - заморозка всего, кромел последнего слоя
LBL6  - функция потерь и оптимизатор
LBL7 -  трансформации данных (train/eval) и путь для сохранения
LBL8 - преобразование картинки в тензор
LBL9 - сохраняем веса модели
LBL10 - если локального .pth нет — пробуем скачать
LBL11 - загружаем чекпойнт PyTorch
LBL12 - восстанавливаем метаданные
LBL13 - подгружаем веса
LBL14 -  обновляем параметры препроцессинга и пересобираем трансформации
LBL15 - переводим модель в режим инференса, отключаем градиенты, проходим по даталоадеру, аккумулируя суммарный loss и число верных предсказаний, а в конце возвращаем средний loss и accuracy в процентах.
LBL16 - преобразуем обучающую и тестовую выборки в DataLoader
LBL17 - фиксируем число эпох (30)
LBL18 - инициализируем списки значений функции потерь и точности на обучающей и тестовой выборке, для дальнейшего отображения их на графике
LBL19 - начинаем цикл обучения
LBL20 - обнуляем градиенты
LBL21 - делаем прямой проход
LBL22 - вычисляем функцию потерь
LBL23 - считаем градиенты и изменяем веса
LBL24 - считаем потери и точность на обучающей выборке
LBL25 - считаем потери и точность на тестовой выборке
LBL26 - выводим потери и точность во время обучения на каждой эпохе
LBL27 - прямой проход модели на тестовом изображении
LBL28 - отображаем график точности на обучающей и тестовой выборках
LBL29 - отображаем график потерь на обучающей и тестовой выборках
